{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681efab8",
   "metadata": {},
   "source": [
    "# DEEP LEARNING FOR SKIN LESIONS\n",
    "\n",
    "This is our primary jupyter notebook for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7847d2f",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd26f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import sklearn stuff\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# set up for plotting figures in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#for image processing\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ac2c3",
   "metadata": {},
   "source": [
    "Phase 1: Load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:      lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "7010 3005\n",
      "1502 1503\n"
     ]
    }
   ],
   "source": [
    "#NOTE: THIS DOWLOAD CODE IS FROM KAGGLEHUB WEBSITE\n",
    "\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"HAM10000_metadata.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load( #changed from load_dataaset cause apparently it's going to be deprecated lol\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kmader/skin-cancer-mnist-ham10000\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())\n",
    "\n",
    "# split off 30% to be validation/test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df['dx'], random_state=42)\n",
    "\n",
    "# split this set (30% of original data) into halves, so 15% val, 15% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['dx'], random_state=42)\n",
    "\n",
    "# print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dd59ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data_frame):\n",
    "    \"\"\"\n",
    "    one hot encoding steps for our dataset.\n",
    "    \n",
    "    data_frame: PD dataframe, data_frame_ that we would like to one hot encode\n",
    "    \n",
    "    \"\"\"\n",
    "    metadata_encoded = data_frame.join(pd.get_dummies(data_frame['dx'], prefix='dx', dtype=int))\n",
    "    metadata_encoded = metadata_encoded.drop(columns=['dx'])\n",
    "\n",
    "    metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dx_type'], prefix='dx_type', dtype=int))\n",
    "    metadata_encoded = metadata_encoded.drop(columns=['dx_type'])\n",
    "\n",
    "    metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['sex'], prefix='sex', dtype=int))\n",
    "    metadata_encoded = metadata_encoded.drop(columns=['sex'])\n",
    "\n",
    "    metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['localization'], prefix='localization', dtype=int))\n",
    "    metadata_encoded = metadata_encoded.drop(columns=['localization'])\n",
    "\n",
    "    metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dataset'], prefix='dataset', dtype=int))\n",
    "    metadata_encoded = metadata_encoded.drop(columns=['dataset'])\n",
    "\n",
    "    columns = ['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df',\n",
    "        'dx_mel', 'dx_nv', 'dx_vasc', 'dx_type_confocal', 'dx_type_consensus',\n",
    "        'dx_type_follow_up', 'dx_type_histo', 'age', 'sex_female', 'sex_male',\n",
    "        'sex_unknown', 'localization_abdomen', 'localization_acral',\n",
    "        'localization_back', 'localization_chest', 'localization_ear',\n",
    "        'localization_face', 'localization_foot', 'localization_genital',\n",
    "        'localization_hand', 'localization_lower extremity',\n",
    "        'localization_neck', 'localization_scalp', 'localization_trunk',\n",
    "        'localization_unknown', 'localization_upper extremity',\n",
    "        'dataset_rosendahl', 'dataset_vidir_modern', 'dataset_vidir_molemax',\n",
    "        'dataset_vienna_dias', 'lesion_id']\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in metadata_encoded.columns:\n",
    "            metadata_encoded[col] = 0\n",
    "\n",
    "    return metadata_encoded\n",
    "\n",
    "def apply_order(data_frame):\n",
    "    \"\"\"\n",
    "    change the order of clumns in the dataframe, add new column names for the newly\n",
    "    one hot encoded variables \n",
    "\n",
    "    data_frame: pandas data_frame, the df we would like to apply changes to \n",
    "    \"\"\"\n",
    "    index = ['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df',\n",
    "        'dx_mel', 'dx_nv', 'dx_vasc', 'dx_type_confocal', 'dx_type_consensus',\n",
    "        'dx_type_follow_up', 'dx_type_histo', 'age', 'sex_female', 'sex_male',\n",
    "        'sex_unknown', 'localization_abdomen', 'localization_acral',\n",
    "        'localization_back', 'localization_chest', 'localization_ear',\n",
    "        'localization_face', 'localization_foot', 'localization_genital',\n",
    "        'localization_hand', 'localization_lower extremity',\n",
    "        'localization_neck', 'localization_scalp', 'localization_trunk',\n",
    "        'localization_unknown', 'localization_upper extremity',\n",
    "        'dataset_rosendahl', 'dataset_vidir_modern', 'dataset_vidir_molemax',\n",
    "        'dataset_vienna_dias', 'lesion_id']\n",
    "\n",
    "    data_frame = data_frame[index]\n",
    "    data_frame = data_frame.drop(columns=['lesion_id'])\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf053a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
      "['histo' 'consensus' 'confocal' 'follow_up']\n",
      "['male' 'female' 'unknown']\n",
      "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
      "['vidir_modern' 'rosendahl' 'vienna_dias' 'vidir_molemax']\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('HAM10000/HAM10000_metadata')\n",
    "metadata.head(5)\n",
    "\n",
    "print(metadata['dx'].unique())\n",
    "print(metadata['dx_type'].unique())\n",
    "print(metadata['sex'].unique())\n",
    "print(metadata['localization'].unique())\n",
    "print(metadata['dataset'].unique())\n",
    "\n",
    "\n",
    "# split off 30% to be validation/test sets\n",
    "train_df, temp_df = train_test_split(metadata, test_size=0.30, stratify=metadata['dx'], random_state=42)\n",
    "\n",
    "# split this set (30% of original data) into halves, so 15% val, 15% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['dx'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09e43ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv',\n",
      "       'dx_vasc', 'dx_type_confocal', 'dx_type_consensus', 'dx_type_follow_up',\n",
      "       'dx_type_histo', 'age', 'sex_female', 'sex_male', 'sex_unknown',\n",
      "       'localization_abdomen', 'localization_acral', 'localization_back',\n",
      "       'localization_chest', 'localization_ear', 'localization_face',\n",
      "       'localization_foot', 'localization_genital', 'localization_hand',\n",
      "       'localization_lower extremity', 'localization_neck',\n",
      "       'localization_scalp', 'localization_trunk', 'localization_unknown',\n",
      "       'localization_upper extremity', 'dataset_rosendahl',\n",
      "       'dataset_vidir_modern', 'dataset_vidir_molemax', 'dataset_vienna_dias'],\n",
      "      dtype='object')\n",
      "(7010, 35)\n",
      "image_id                        ISIC_0031775\n",
      "dx_akiec                                   0\n",
      "dx_bcc                                     0\n",
      "dx_bkl                                     0\n",
      "dx_df                                      0\n",
      "dx_mel                                     0\n",
      "dx_nv                                      1\n",
      "dx_vasc                                    0\n",
      "dx_type_confocal                           0\n",
      "dx_type_consensus                          0\n",
      "dx_type_follow_up                          1\n",
      "dx_type_histo                              0\n",
      "age                                     60.0\n",
      "sex_female                                 0\n",
      "sex_male                                   1\n",
      "sex_unknown                                0\n",
      "localization_abdomen                       0\n",
      "localization_acral                         0\n",
      "localization_back                          0\n",
      "localization_chest                         0\n",
      "localization_ear                           0\n",
      "localization_face                          0\n",
      "localization_foot                          0\n",
      "localization_genital                       0\n",
      "localization_hand                          0\n",
      "localization_lower extremity               0\n",
      "localization_neck                          0\n",
      "localization_scalp                         0\n",
      "localization_trunk                         1\n",
      "localization_unknown                       0\n",
      "localization_upper extremity               0\n",
      "dataset_rosendahl                          0\n",
      "dataset_vidir_modern                       0\n",
      "dataset_vidir_molemax                      1\n",
      "dataset_vienna_dias                        0\n",
      "Name: 4357, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Processing the test set\n",
    "\n",
    "train_df = one_hot_encode(train_df)\n",
    "train_df = apply_order(train_df)\n",
    "print(train_df.columns)\n",
    "print(train_df.shape)\n",
    "print(train_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae94e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv',\n",
      "       'dx_vasc', 'dx_type_confocal', 'dx_type_consensus', 'dx_type_follow_up',\n",
      "       'dx_type_histo', 'age', 'sex_female', 'sex_male', 'sex_unknown',\n",
      "       'localization_abdomen', 'localization_acral', 'localization_back',\n",
      "       'localization_chest', 'localization_ear', 'localization_face',\n",
      "       'localization_foot', 'localization_genital', 'localization_hand',\n",
      "       'localization_lower extremity', 'localization_neck',\n",
      "       'localization_scalp', 'localization_trunk', 'localization_unknown',\n",
      "       'localization_upper extremity', 'dataset_rosendahl',\n",
      "       'dataset_vidir_modern', 'dataset_vidir_molemax', 'dataset_vienna_dias'],\n",
      "      dtype='object')\n",
      "(1502, 35)\n",
      "image_id                        ISIC_0032982\n",
      "dx_akiec                                   0\n",
      "dx_bcc                                     0\n",
      "dx_bkl                                     0\n",
      "dx_df                                      0\n",
      "dx_mel                                     1\n",
      "dx_nv                                      0\n",
      "dx_vasc                                    0\n",
      "dx_type_confocal                           0\n",
      "dx_type_consensus                          0\n",
      "dx_type_follow_up                          0\n",
      "dx_type_histo                              1\n",
      "age                                     20.0\n",
      "sex_female                                 0\n",
      "sex_male                                   1\n",
      "sex_unknown                                0\n",
      "localization_abdomen                       0\n",
      "localization_acral                         0\n",
      "localization_back                          1\n",
      "localization_chest                         0\n",
      "localization_ear                           0\n",
      "localization_face                          0\n",
      "localization_foot                          0\n",
      "localization_genital                       0\n",
      "localization_hand                          0\n",
      "localization_lower extremity               0\n",
      "localization_neck                          0\n",
      "localization_scalp                         0\n",
      "localization_trunk                         0\n",
      "localization_unknown                       0\n",
      "localization_upper extremity               0\n",
      "dataset_rosendahl                          0\n",
      "dataset_vidir_modern                       1\n",
      "dataset_vidir_molemax                      0\n",
      "dataset_vienna_dias                        0\n",
      "Name: 1800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Processing the Validation set\n",
    "\n",
    "val_df = one_hot_encode(val_df)\n",
    "val_df = apply_order(val_df)\n",
    "print(val_df.columns)\n",
    "print(val_df.shape)\n",
    "print(val_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b73f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv',\n",
      "       'dx_vasc', 'dx_type_confocal', 'dx_type_consensus', 'dx_type_follow_up',\n",
      "       'dx_type_histo', 'age', 'sex_female', 'sex_male', 'sex_unknown',\n",
      "       'localization_abdomen', 'localization_acral', 'localization_back',\n",
      "       'localization_chest', 'localization_ear', 'localization_face',\n",
      "       'localization_foot', 'localization_genital', 'localization_hand',\n",
      "       'localization_lower extremity', 'localization_neck',\n",
      "       'localization_scalp', 'localization_trunk', 'localization_unknown',\n",
      "       'localization_upper extremity', 'dataset_rosendahl',\n",
      "       'dataset_vidir_modern', 'dataset_vidir_molemax', 'dataset_vienna_dias'],\n",
      "      dtype='object')\n",
      "(1503, 35)\n",
      "image_id                        ISIC_0031580\n",
      "dx_akiec                                   0\n",
      "dx_bcc                                     0\n",
      "dx_bkl                                     1\n",
      "dx_df                                      0\n",
      "dx_mel                                     0\n",
      "dx_nv                                      0\n",
      "dx_vasc                                    0\n",
      "dx_type_confocal                           0\n",
      "dx_type_consensus                          0\n",
      "dx_type_follow_up                          0\n",
      "dx_type_histo                              1\n",
      "age                                     40.0\n",
      "sex_female                                 0\n",
      "sex_male                                   1\n",
      "sex_unknown                                0\n",
      "localization_abdomen                       0\n",
      "localization_acral                         0\n",
      "localization_back                          0\n",
      "localization_chest                         0\n",
      "localization_ear                           0\n",
      "localization_face                          0\n",
      "localization_foot                          0\n",
      "localization_genital                       0\n",
      "localization_hand                          0\n",
      "localization_lower extremity               0\n",
      "localization_neck                          0\n",
      "localization_scalp                         0\n",
      "localization_trunk                         0\n",
      "localization_unknown                       0\n",
      "localization_upper extremity               1\n",
      "dataset_rosendahl                          1\n",
      "dataset_vidir_modern                       0\n",
      "dataset_vidir_molemax                      0\n",
      "dataset_vienna_dias                        0\n",
      "Name: 547, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Processing the Test set\n",
    "\n",
    "test_df = one_hot_encode(test_df)\n",
    "test_df = apply_order(test_df)\n",
    "print(test_df.columns)\n",
    "print(test_df.shape)\n",
    "print(test_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv', 'dx_vasc']\n",
    "# #TRAIN SET: note that features are represnted by x, labels by y\n",
    "# #labels \n",
    "# train_df_y = train_df[labels].copy()\n",
    "# #features\n",
    "# train_df_x = train_df.drop(columns=labels)\n",
    "\n",
    "# #VALIDATION SET:\n",
    "# #labels \n",
    "# val_df_y = val_df[labels].copy()\n",
    "# #features\n",
    "# val_df_x = val_df.drop(columns=labels)\n",
    "\n",
    "# #TEST SET:\n",
    "# #labels \n",
    "# test_df_y = test_df[labels].copy()\n",
    "# #features\n",
    "# test_df_x = test_df.drop(columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7010, 35)\n",
      "(7010, 28)\n",
      "(7010, 7)\n",
      "\n",
      "image_id                        ISIC_0031775\n",
      "dx_type_confocal                           0\n",
      "dx_type_consensus                          0\n",
      "dx_type_follow_up                          1\n",
      "dx_type_histo                              0\n",
      "age                                     60.0\n",
      "sex_female                                 0\n",
      "sex_male                                   1\n",
      "sex_unknown                                0\n",
      "localization_abdomen                       0\n",
      "localization_acral                         0\n",
      "localization_back                          0\n",
      "localization_chest                         0\n",
      "localization_ear                           0\n",
      "localization_face                          0\n",
      "localization_foot                          0\n",
      "localization_genital                       0\n",
      "localization_hand                          0\n",
      "localization_lower extremity               0\n",
      "localization_neck                          0\n",
      "localization_scalp                         0\n",
      "localization_trunk                         1\n",
      "localization_unknown                       0\n",
      "localization_upper extremity               0\n",
      "dataset_rosendahl                          0\n",
      "dataset_vidir_modern                       0\n",
      "dataset_vidir_molemax                      1\n",
      "dataset_vienna_dias                        0\n",
      "Name: 4357, dtype: object\n",
      "\n",
      "dx_akiec    0\n",
      "dx_bcc      0\n",
      "dx_bkl      0\n",
      "dx_df       0\n",
      "dx_mel      0\n",
      "dx_nv       1\n",
      "dx_vasc     0\n",
      "Name: 4357, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# #sanity check\n",
    "# print(train_df.shape)\n",
    "# print(train_df_x.shape)\n",
    "# print(train_df_y.shape)\n",
    "# print()\n",
    "# print(train_df_x.iloc[0])\n",
    "# print()\n",
    "# print(train_df_y.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27c79b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make our dataframe into indexible dicts so that we can easily match metadata to img\n",
    "train_df_dict = train_df.set_index('image_id').to_dict(orient='index')\n",
    "val_df_dict = val_df.set_index('image_id').to_dict(orient='index')\n",
    "test_df_dict = test_df.set_index('image_id').to_dict(orient='index')\n",
    "\n",
    "# train_df_dict_x = train_df_x.set_index('image_id').to_dict(orient='index')\n",
    "# val_df_dict_x = val_df_x.set_index('image_id').to_dict(orient='index')\n",
    "# test_df_dict_x = test_df_x.set_index('image_id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e95eb461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n",
      "34\n",
      "{'dx_akiec': 0, 'dx_bcc': 0, 'dx_bkl': 0, 'dx_df': 0, 'dx_mel': 0, 'dx_nv': 1, 'dx_vasc': 0, 'dx_type_confocal': 0, 'dx_type_consensus': 0, 'dx_type_follow_up': 1, 'dx_type_histo': 0, 'age': 45.0, 'sex_female': 0, 'sex_male': 1, 'sex_unknown': 0, 'localization_abdomen': 0, 'localization_acral': 0, 'localization_back': 0, 'localization_chest': 0, 'localization_ear': 0, 'localization_face': 0, 'localization_foot': 0, 'localization_genital': 0, 'localization_hand': 0, 'localization_lower extremity': 0, 'localization_neck': 0, 'localization_scalp': 0, 'localization_trunk': 1, 'localization_unknown': 0, 'localization_upper extremity': 0, 'dataset_rosendahl': 0, 'dataset_vidir_modern': 0, 'dataset_vidir_molemax': 1, 'dataset_vienna_dias': 0}\n"
     ]
    }
   ],
   "source": [
    "#sanity check, this img is only in test_df.\n",
    "print(len(test_df_dict['ISIC_0027419']))\n",
    "\n",
    "#this should only be in train\n",
    "print(len(train_df_dict['ISIC_0029306']))\n",
    "\n",
    "#this should only be in train\n",
    "print(len(train_df_dict['ISIC_0024306']))\n",
    "print(train_df_dict['ISIC_0024306'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b8c9",
   "metadata": {},
   "source": [
    "Image Processing + Input to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5beb293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM10000/HAM10000_part1\\ISIC_0024306.jpg\n",
      "HAM10000/HAM10000_part2\\ISIC_0029306.jpg\n",
      "HAM10000/HAM10000_part1\\ISIC_0024306.jpg\n",
      "HAM10000/HAM10000_part2\\ISIC_0029306.jpg\n"
     ]
    }
   ],
   "source": [
    "#get the path for each image\n",
    "#ham10000_pt1 has the paths for all images in the ham10000_pt1 folder, same for pt2.\n",
    "ham10000_pt1 = glob('HAM10000/HAM10000_part1/*.jpg')\n",
    "ham1000_pt2 = glob('HAM10000/HAM10000_part2/*.jpg')\n",
    "\n",
    "print(ham10000_pt1[0])\n",
    "print(ham1000_pt2[0])\n",
    "\n",
    "combined_folder_paths = ham10000_pt1 + ham1000_pt2\n",
    "print(combined_folder_paths[0])\n",
    "print(combined_folder_paths[len(ham10000_pt1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4d83080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the metadata a pandas dataframe\n",
    "\n",
    "def print_data(image_id, row, flattened_image_np, total_data, i):\n",
    "    \"\"\" \n",
    "    Function that prints the data so that differences can be spotted.\n",
    "    intended to be used inside of process data for testing.\n",
    "    image_id: string, the image id. (eg ISIC_0024306)\n",
    "    row: list, metadat info\n",
    "    flattened_image_np: np array, flattened image info\n",
    "    total_data: pandas df, the master dataframe\n",
    "    i: int, iterator\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"----------------------------\")\n",
    "    print()\n",
    "    print(\"image_id: \", image_id)\n",
    "    print(\"first 10 of the metadata: \", row[:10])\n",
    "    print(\"last 10 entries of the flattened_image_np array: \", flattened_image_np[-10:])\n",
    "    print(\"total data row that was just created: \", total_data.iloc[i].to_frame().T)\n",
    "    print()\n",
    "\n",
    "def add_to_list(image_id, dict_frame, flattened_image_np, final_res):\n",
    "    \"\"\" \n",
    "    This is a function to help add the pixel array pertaining to image_id to the specified list\n",
    "\n",
    "    image_id: string, the id of the image\n",
    "    dict_frame: a pandas data frame, the one that we search from\n",
    "    flattened_image_np: numpy array, pixelized flattened version of the image\n",
    "    final_res: an array, the one that we want to be appending to \n",
    "    \"\"\"\n",
    "    #print(\"IN ADD_TO_DF\")\n",
    "    metadata_row = dict_frame[image_id] \n",
    "    #print(metadata_row)\n",
    "    #row data needs to be changed to np array of alues cause we made it key alue pairs\n",
    "    metadata_row_np = np.array(list(metadata_row.values()))\n",
    "\n",
    "    obs = np.concatenate((metadata_row_np, flattened_image_np))\n",
    "    # obs_df = pd.DataFrame([obs])\n",
    "    # final_res = pd.concat([final_res, obs_df], ignore_index=True)\n",
    "    final_res.append(obs)\n",
    "    \n",
    "def process_data(folder, test_df_dict, val_df_dict, train_df_dict):\n",
    "    \"\"\"\n",
    "    function that processes the data from HAM10000\n",
    "\n",
    "    folder: a list, holds the names of all the paths in the folder\n",
    "    test_df_dict_x: pd dataframe, converted to a dict, so that we can index by img id\n",
    "    train_df_dict_x: pd dataframe, converted to a dict, so that we can index by img id\n",
    "    val_df_dict_x: pd dataframe, converted to a dict, so that we can index by img id\n",
    "\n",
    "    \"\"\"\n",
    "    # test_ISIC_ids = set(test_df_x.keys)\n",
    "    # val_ISIC_ids = set(val_df_x.keys)\n",
    "    # print(\"ISIC_0024306\" in test_ISIC_ids)\n",
    "    # print(\"ISIC_0024306\" in val_ISIC_ids)\n",
    "    #train_ISIC_ids = set(train_df_x[\"image_id\"])\n",
    "    train_final = [] \n",
    "    test_final = [] \n",
    "    val_final = []\n",
    "    for i in range(len(folder)):\n",
    "        #open the image\n",
    "        path = folder[i]\n",
    "        image = Image.open(path)\n",
    "\n",
    "        image_id = path[24:len(path)-4]\n",
    "\n",
    "        #resize it, this will keep the aspect ratio\n",
    "        image.thumbnail((100, 100))\n",
    "\n",
    "        #make our image into a series of pixes, MxNx3\n",
    "        img_array = np.array(image) \n",
    "        #flatten the 3D matrix\n",
    "        flattened_array = img_array.flatten()\n",
    "        flattened_image_np = np.array(flattened_array) / 255.0\n",
    "\n",
    "        #something like\n",
    "        #if imag_id in val_df_x then row = test_df_x[image_id]\n",
    "        #else if image_id in train_df_x then row = train_df_x[image_id]\n",
    "        #else we know its in train_df_x so row = train_df_x[image_id]\n",
    "        #whih is probs better cause test set is gonna be huge, so we \n",
    "        #don't wanna be looking through that thing\n",
    "        if image_id in test_df_dict:\n",
    "            add_to_list(image_id,test_df_dict, flattened_image_np, test_final)\n",
    "        elif image_id in val_df_dict:\n",
    "            add_to_list(image_id,val_df_dict, flattened_image_np, val_final)\n",
    "        else:\n",
    "            add_to_list(image_id, train_df_dict, flattened_image_np, train_final)\n",
    "\n",
    "        if(i%1000 == 0) and i != 0:\n",
    "            #print_data(image_id, row, flattened_image_np, data_frame, i)\n",
    "            print(\"!! finished batch of 1000 !!\")\n",
    "            print(\"test final len: \", len(test_final))\n",
    "            print(\"some output of final_en: \", test_final[-1])\n",
    "            print(\"val_final shape: \", len(val_final))\n",
    "            print(\"some output of val_final: \", val_final[-1])\n",
    "            print(\"train_final shape\", len(train_final))\n",
    "            print(\"some output of train_final: \", train_final[-1])\n",
    "    \n",
    "    return (pd.DataFrame(train_final), pd.DataFrame(val_final), pd.DataFrame(test_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ccc2dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! finished batch of 1000 !!\n",
      "test final len:  158\n",
      "some output of final_en:  [0.         0.         0.         ... 0.84705882 0.58431373 0.57647059]\n",
      "val_final shape:  153\n",
      "some output of val_final:  [0.         0.         0.         ... 0.81176471 0.55686275 0.53333333]\n",
      "train_final shape 690\n",
      "some output of train_final:  [0.         0.         0.         ... 0.88627451 0.6        0.64313725]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  310\n",
      "some output of final_en:  [0.         0.         0.         ... 0.7372549  0.39607843 0.3372549 ]\n",
      "val_final shape:  306\n",
      "some output of val_final:  [0.         0.         0.         ... 0.78039216 0.56862745 0.53333333]\n",
      "train_final shape 1385\n",
      "some output of train_final:  [0.         0.         0.         ... 0.82352941 0.49803922 0.49019608]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  483\n",
      "some output of final_en:  [0.         0.         0.         ... 0.83921569 0.6        0.49803922]\n",
      "val_final shape:  448\n",
      "some output of val_final:  [0.         0.         0.         ... 0.70588235 0.62745098 0.65098039]\n",
      "train_final shape 2070\n",
      "some output of train_final:  [0.         0.         0.         ... 0.9254902  0.77254902 0.85098039]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  628\n",
      "some output of final_en:  [0.         0.         0.         ... 0.83529412 0.6627451  0.72156863]\n",
      "val_final shape:  605\n",
      "some output of val_final:  [0.         0.         0.         ... 0.49411765 0.38823529 0.3372549 ]\n",
      "train_final shape 2768\n",
      "some output of train_final:  [0.         0.         0.         ... 0.51372549 0.3254902  0.37647059]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  772\n",
      "some output of final_en:  [0.         0.         1.         ... 0.65882353 0.56470588 0.63529412]\n",
      "val_final shape:  752\n",
      "some output of val_final:  [0.         0.         0.         ... 0.8745098  0.6627451  0.71372549]\n",
      "train_final shape 3477\n",
      "some output of train_final:  [0.         0.         0.         ... 0.7372549  0.60784314 0.52941176]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  921\n",
      "some output of final_en:  [0.         0.         0.         ... 0.79215686 0.6        0.61568627]\n",
      "val_final shape:  909\n",
      "some output of val_final:  [0.         0.         0.         ... 0.71764706 0.44313725 0.47058824]\n",
      "train_final shape 4171\n",
      "some output of train_final:  [0.         0.         0.         ... 0.79215686 0.50196078 0.48627451]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  1054\n",
      "some output of final_en:  [0.         0.         0.         ... 0.63529412 0.44705882 0.30588235]\n",
      "val_final shape:  1072\n",
      "some output of val_final:  [0.         0.         0.         ... 0.88235294 0.68235294 0.8       ]\n",
      "train_final shape 4875\n",
      "some output of train_final:  [0.         0.         0.         ... 0.85882353 0.6627451  0.6627451 ]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  1203\n",
      "some output of final_en:  [0.         0.         0.         ... 0.68235294 0.54117647 0.61568627]\n",
      "val_final shape:  1205\n",
      "some output of val_final:  [0.         0.         1.         ... 0.15686275 0.08235294 0.12156863]\n",
      "train_final shape 5593\n",
      "some output of train_final:  [0.         0.         0.         ... 0.8745098  0.63921569 0.52941176]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  1359\n",
      "some output of final_en:  [0. 0. 0. ... 0. 0. 0.]\n",
      "val_final shape:  1360\n",
      "some output of val_final:  [0.         0.         1.         ... 0.44313725 0.30588235 0.31372549]\n",
      "train_final shape 6282\n",
      "some output of train_final:  [0.         0.         1.         ... 0.67843137 0.60784314 0.70196078]\n",
      "!! finished batch of 1000 !!\n",
      "test final len:  1500\n",
      "some output of final_en:  [0.         0.         0.         ... 0.70196078 0.49411765 0.49803922]\n",
      "val_final shape:  1499\n",
      "some output of val_final:  [0.         0.         0.         ... 0.59607843 0.55686275 0.62352941]\n",
      "train_final shape 7002\n",
      "some output of train_final:  [0.         1.         0.         ... 0.01568627 0.01568627 0.01568627]\n"
     ]
    }
   ],
   "source": [
    "#Appending all of the pixels to the metadata sets!!! RAAHHH\n",
    "train_final, val_final, test_final = process_data(combined_folder_paths, test_df_dict, val_df_dict, train_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e9a7f01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7010, 22534)\n",
      "(1503, 22534)\n",
      "(1502, 22534)\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(train_final.shape)\n",
    "print(test_final.shape)\n",
    "print(val_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bfb3a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we iterated in order of the image ids we need to shuffle each set again\n",
    "shuffled_train_final = train_final.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_test_final = test_final.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_val_final = val_final.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a9a8af9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([         'dx_akiec',            'dx_bcc',            'dx_bkl',\n",
      "                   'dx_df',            'dx_mel',             'dx_nv',\n",
      "                 'dx_vasc',  'dx_type_confocal', 'dx_type_consensus',\n",
      "       'dx_type_follow_up',\n",
      "       ...\n",
      "                     22524,               22525,               22526,\n",
      "                     22527,               22528,               22529,\n",
      "                     22530,               22531,               22532,\n",
      "                     22533],\n",
      "      dtype='object', length=22534)\n",
      "22500\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_test_final.columns)\n",
    "# add in the metadata column names back in\n",
    "index_names = ['dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df',\n",
    "    'dx_mel', 'dx_nv', 'dx_vasc', 'dx_type_confocal', 'dx_type_consensus',\n",
    "    'dx_type_follow_up', 'dx_type_histo', 'age', 'sex_female', 'sex_male',\n",
    "    'sex_unknown', 'localization_abdomen', 'localization_acral',\n",
    "    'localization_back', 'localization_chest', 'localization_ear',\n",
    "    'localization_face', 'localization_foot', 'localization_genital',\n",
    "    'localization_hand', 'localization_lower extremity',\n",
    "    'localization_neck', 'localization_scalp', 'localization_trunk',\n",
    "    'localization_unknown', 'localization_upper extremity',\n",
    "    'dataset_rosendahl', 'dataset_vidir_modern', 'dataset_vidir_molemax',\n",
    "    'dataset_vienna_dias']\n",
    "print(shuffled_train_final.shape[1] - len(index_names))\n",
    "\n",
    "#for pixels just i \n",
    "for i in range(len(index_names), shuffled_train_final.shape[1]):\n",
    "    index_names.append(i)\n",
    "\n",
    "shuffled_train_final.columns = index_names\n",
    "shuffled_test_final.columns = index_names\n",
    "shuffled_val_final.columns = index_names\n",
    "\n",
    "#print(shuffled_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b0cd530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv', 'dx_vasc']\n",
    "#Now that all of the metadata is sorted out, pop off the labels\n",
    "\n",
    "#TRAIN SET: note that features are represnted by x, labels by y\n",
    "#labels \n",
    "shuffled_train_final_y = shuffled_train_final[labels].copy()\n",
    "    #train_df_y = train_df[labels].copy()\n",
    "#features\n",
    "shuffled_train_final_x = shuffled_train_final.drop(columns=labels)\n",
    "    #train_df_x = train_df.drop(columns=labels)\n",
    "\n",
    "#VALIDATION SET:\n",
    "#labels \n",
    "shuffled_val_final_y = shuffled_val_final[labels].copy()\n",
    "    #val_df_y = val_df[labels].copy()\n",
    "#features\n",
    "shuffled_val_final_x = shuffled_val_final.drop(columns=labels)\n",
    "    #val_df_x = val_df.drop(columns=labels)\n",
    "\n",
    "#TEST SET:\n",
    "#labels \n",
    "shuffled_test_final_y = shuffled_test_final[labels].copy()\n",
    "    #test_df_y = test_df[labels].copy()\n",
    "#features\n",
    "shuffled_test_final_x = shuffled_test_final.drop(columns=labels)\n",
    "    #test_df_x = test_df.drop(columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e2e36909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAHHHHHHHHHHHHHHHHHH PUT IT IN A CSVVVV\n",
    "shuffled_train_final_y.to_csv('shuffled_train_final_y.csv', index=False)\n",
    "shuffled_train_final_x.to_csv('shuffled_train_final_x.csv', index=False)\n",
    "\n",
    "shuffled_val_final_y.to_csv('shuffled_val_final_y.csv', index=False)\n",
    "shuffled_val_final_x.to_csv('shuffled_val_final_x.csv', index=False)\n",
    "\n",
    "shuffled_test_final_y.to_csv('shuffled_test_final_y.csv', index=False)\n",
    "shuffled_test_final_x.to_csv('shuffled_test_final_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefa4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
