{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681efab8",
   "metadata": {},
   "source": [
    "# DEEP LEARNING FOR SKIN LESIONS\n",
    "\n",
    "This is our primary jupyter notebook for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7847d2f",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd26f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import sklearn stuff\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# set up for plotting figures in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#for image processing\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ac2c3",
   "metadata": {},
   "source": [
    "Phase 1: Load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:      lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "7010 3005\n",
      "1502 1503\n"
     ]
    }
   ],
   "source": [
    "#NOTE: THIS DOWLOAD CODE IS FROM KAGGLEHUB WEBSITE\n",
    "\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"HAM10000_metadata.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load( #changed from load_dataaset cause apparently it's going to be deprecated lol\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kmader/skin-cancer-mnist-ham10000\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())\n",
    "\n",
    "# split off 30% to be validation/test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df['dx'], random_state=42)\n",
    "\n",
    "# split this set (30% of original data) into halves, so 15% val, 15% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['dx'], random_state=42)\n",
    "\n",
    "# print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf053a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
      "['histo' 'consensus' 'confocal' 'follow_up']\n",
      "['male' 'female' 'unknown']\n",
      "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
      "['vidir_modern' 'rosendahl' 'vienna_dias' 'vidir_molemax']\n",
      "Index(['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv',\n",
      "       'dx_vasc', 'dx_type_confocal', 'dx_type_consensus', 'dx_type_follow_up',\n",
      "       'dx_type_histo', 'age', 'sex_female', 'sex_male', 'sex_unknown',\n",
      "       'localization_abdomen', 'localization_acral', 'localization_back',\n",
      "       'localization_chest', 'localization_ear', 'localization_face',\n",
      "       'localization_foot', 'localization_genital', 'localization_hand',\n",
      "       'localization_lower extremity', 'localization_neck',\n",
      "       'localization_scalp', 'localization_trunk', 'localization_unknown',\n",
      "       'localization_upper extremity', 'dataset_rosendahl',\n",
      "       'dataset_vidir_modern', 'dataset_vidir_molemax', 'dataset_vienna_dias'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('HAM10000/HAM10000_metadata')\n",
    "metadata.head(5)\n",
    "\n",
    "print(metadata['dx'].unique())\n",
    "print(metadata['dx_type'].unique())\n",
    "print(metadata['sex'].unique())\n",
    "print(metadata['localization'].unique())\n",
    "print(metadata['dataset'].unique())\n",
    "\n",
    "metadata_encoded = metadata.join(pd.get_dummies(metadata['dx'], prefix='dx', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dx'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dx_type'], prefix='dx_type', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dx_type'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['sex'], prefix='sex', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['sex'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['localization'], prefix='localization', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['localization'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dataset'], prefix='dataset', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dataset'])\n",
    "\n",
    "new_order = ['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
    "['histo' 'consensus' 'confocal' 'follow_up']\n",
    "['male' 'female' 'unknown']\n",
    "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
    " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
    "['vidir_modern' 'rosendahl' 'vienna_dias' 'vidir_molemax']\n",
    "index = ['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df',\n",
    "       'dx_mel', 'dx_nv', 'dx_vasc', 'dx_type_confocal', 'dx_type_consensus',\n",
    "       'dx_type_follow_up', 'dx_type_histo', 'age', 'sex_female', 'sex_male',\n",
    "       'sex_unknown', 'localization_abdomen', 'localization_acral',\n",
    "       'localization_back', 'localization_chest', 'localization_ear',\n",
    "       'localization_face', 'localization_foot', 'localization_genital',\n",
    "       'localization_hand', 'localization_lower extremity',\n",
    "       'localization_neck', 'localization_scalp', 'localization_trunk',\n",
    "       'localization_unknown', 'localization_upper extremity',\n",
    "       'dataset_rosendahl', 'dataset_vidir_modern', 'dataset_vidir_molemax',\n",
    "       'dataset_vienna_dias', 'lesion_id']\n",
    "\n",
    "metadata_encoded = metadata_encoded[index]\n",
    "metadata_encoded = metadata_encoded.drop(columns=['lesion_id'])\n",
    "print(metadata_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c79b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "metadata_encoded = metadata_encoded.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "# print(len(metadata_encoded['ISIC_0027419']))\n",
    "# print(len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b8c9",
   "metadata": {},
   "source": [
    "Image Processing + Input to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM10000/HAM10000_part1\\ISIC_0024306.jpg\n",
      "HAM10000/HAM10000_part2\\ISIC_0029306.jpg\n"
     ]
    }
   ],
   "source": [
    "#get the path for each image\n",
    "#ham10000_pt1 has the paths for all images in the ham10000_pt1 folder, same for pt2.\n",
    "ham10000_pt1 = glob('HAM10000/HAM10000_part1/*.jpg')\n",
    "ham1000_pt2 = glob('HAM10000/HAM10000_part2/*.jpg')\n",
    "\n",
    "print(ham10000_pt1[0])\n",
    "print(ham1000_pt2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the metadata a pandas dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4e8fdf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     22\u001b[39m image = image.thumbnail((\u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#image.save('image_thumbnail.jpg')\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#print(image.size) # Output: (100, 100)\u001b[39;00m\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#make our image into a series of pixes, MxNx3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m image_to_pixels = \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m#flatten the 3D matrix\u001b[39;00m\n\u001b[32m     31\u001b[39m flattened_array = np.flatten(image_to_pixels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:2614\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(fname, format)\u001b[39m\n\u001b[32m   2610\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib.image.imread)\n\u001b[32m   2611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimread\u001b[39m(\n\u001b[32m   2612\u001b[39m         fname: \u001b[38;5;28mstr\u001b[39m | pathlib.Path | BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2613\u001b[39m ) -> np.ndarray:\n\u001b[32m-> \u001b[39m\u001b[32m2614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\matplotlib\\image.py:1520\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(fname, format)\u001b[39m\n\u001b[32m   1513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse.urlparse(fname).scheme) > \u001b[32m1\u001b[39m:\n\u001b[32m   1514\u001b[39m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1516\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease open the URL for reading and pass the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1517\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresult to Pillow, e.g. with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1518\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1519\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[32m   1521\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[32m   1522\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL.PngImagePlugin.PngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m   1523\u001b[39m             pil_to_array(image))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:148\u001b[39m, in \u001b[36mImageFile.__init__\u001b[39m\u001b[34m(self, fp, filename)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    150\u001b[39m         \u001b[38;5;167;01mIndexError\u001b[39;00m,  \u001b[38;5;66;03m# end of data\u001b[39;00m\n\u001b[32m    151\u001b[39m         \u001b[38;5;167;01mTypeError\u001b[39;00m,  \u001b[38;5;66;03m# end of data (ord)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m         struct.error,\n\u001b[32m    155\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[32m    156\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(v) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mv\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:760\u001b[39m, in \u001b[36mPngImageFile._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _accept(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(\u001b[32m8\u001b[39m)):\n\u001b[32m    761\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mnot a PNG file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    762\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(msg)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "#DATA PROCESSING FOR GENERAL CLASSIFIERS\n",
    "\n",
    "#loop oer each image\n",
    "    #resize \n",
    "    #flatten the 3d array\n",
    "    #each row create a mapping\n",
    "    #process the metadata(ex: mapping labels to numbers)\n",
    "    #add all of the info to the accum numpy array \n",
    "#\n",
    "\n",
    "pixel_rep = []\n",
    "\n",
    "total_data = pd.DataFrame()\n",
    "\n",
    "for path in ham10000_pt1:\n",
    "    #open the image\n",
    "    image = Image.open(path)\n",
    "\n",
    "    image_id = path[25:len(path)]\n",
    "\n",
    "    #resize it, this will keep the aspect ratio\n",
    "    image = image.thumbnail((100, 100))\n",
    "\n",
    "    #image.save('image_thumbnail.jpg')\n",
    "    #print(image.size) # Output: (100, 100)\n",
    "\n",
    "    #make our image into a series of pixes, MxNx3\n",
    "    image_to_pixels = plt.imread(image)\n",
    "\n",
    "    #flatten the 3D matrix\n",
    "    flattened_array = np.flatten(image_to_pixels)\n",
    "    print(flattened_array)\n",
    "    break\n",
    "\n",
    "    #process all of the metadata\n",
    "    \n",
    "\n",
    "    #need to add all of the metadata accosiated with this image\n",
    "    # obseration = metadata[image_id]\n",
    "    # np.insert(flattened_array,0, obseration)\n",
    "    #pixel_rep.append(plt.imread(image))\n",
    "\n",
    "# for path in ham1000_pt2:\n",
    "    #pixel_rep.append(plt.imread(path))\n",
    "\n",
    "\n",
    "#column_names = [\"dx\",\"dx_type\",\"age\",\"sex\",\"localization\",\"dataset\", \"pixel0\", \"pixel1\", etc]\n",
    "\n",
    "\n",
    "\n",
    "# print(\"-----Results of reading in the image with imread-----\")\n",
    "# print(\"First item in the array:\")\n",
    "# print(pixel_rep[0])\n",
    "\n",
    "# print(img_test)\n",
    "# print(ham1000_pt2[0])\n",
    "# print(ham10000_pt1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10015\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(10015, 450, 600, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pixel_rep))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:871\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    863\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    864\u001b[39m             arrays,\n\u001b[32m    865\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m             typ=manager,\n\u001b[32m    869\u001b[39m         )\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m         mgr = \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    880\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    881\u001b[39m         {},\n\u001b[32m    882\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    885\u001b[39m         typ=manager,\n\u001b[32m    886\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:319\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    314\u001b[39m     values = _ensure_2d(values)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     values = \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m values.dtype != dtype:\n\u001b[32m    322\u001b[39m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[32m    323\u001b[39m     values = sanitize_array(\n\u001b[32m    324\u001b[39m         values,\n\u001b[32m    325\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    328\u001b[39m         allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    329\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:582\u001b[39m, in \u001b[36m_prep_ndarraylike\u001b[39m\u001b[34m(values, copy)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    580\u001b[39m     values = convert(values)\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marke\\Downloads\\ComputerScience\\DeepLearningForSkinLesions\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[39m, in \u001b[36m_ensure_2d\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    590\u001b[39m     values = values.reshape((values.shape[\u001b[32m0\u001b[39m], \u001b[32m1\u001b[39m))\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m values.ndim != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[31mValueError\u001b[39m: Must pass 2-d input. shape=(10015, 450, 600, 3)"
     ]
    }
   ],
   "source": [
    "print(len(pixel_rep))\n",
    "\n",
    "#pd.DataFrame(pixel_rep, columns=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62641f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diide each RGB by 255 to get numbers in range 0 - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
