{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681efab8",
   "metadata": {},
   "source": [
    "# DEEP LEARNING FOR SKIN LESIONS\n",
    "\n",
    "This is our primary jupyter notebook for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7847d2f",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd26f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import sklearn stuff\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# set up for plotting figures in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#for image processing\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ac2c3",
   "metadata": {},
   "source": [
    "Phase 1: Load in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records:      lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n",
      "7010 3005\n",
      "1502 1503\n"
     ]
    }
   ],
   "source": [
    "#NOTE: THIS DOWLOAD CODE IS FROM KAGGLEHUB WEBSITE\n",
    "\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"HAM10000_metadata.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load( #changed from load_dataaset cause apparently it's going to be deprecated lol\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"kmader/skin-cancer-mnist-ham10000\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())\n",
    "\n",
    "# split off 30% to be validation/test sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df['dx'], random_state=42)\n",
    "\n",
    "# split this set (30% of original data) into halves, so 15% val, 15% test\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['dx'], random_state=42)\n",
    "\n",
    "# print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf053a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
      "['histo' 'consensus' 'confocal' 'follow_up']\n",
      "['male' 'female' 'unknown']\n",
      "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
      "['vidir_modern' 'rosendahl' 'vienna_dias' 'vidir_molemax']\n",
      "Index(['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df', 'dx_mel', 'dx_nv',\n",
      "       'dx_vasc', 'dx_type_confocal', 'dx_type_consensus', 'dx_type_follow_up',\n",
      "       'dx_type_histo', 'age', 'sex_female', 'sex_male', 'sex_unknown',\n",
      "       'localization_abdomen', 'localization_acral', 'localization_back',\n",
      "       'localization_chest', 'localization_ear', 'localization_face',\n",
      "       'localization_foot', 'localization_genital', 'localization_hand',\n",
      "       'localization_lower extremity', 'localization_neck',\n",
      "       'localization_scalp', 'localization_trunk', 'localization_unknown',\n",
      "       'localization_upper extremity', 'dataset_rosendahl',\n",
      "       'dataset_vidir_modern', 'dataset_vidir_molemax', 'dataset_vienna_dias'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('HAM10000/HAM10000_metadata')\n",
    "metadata.head(5)\n",
    "\n",
    "print(metadata['dx'].unique())\n",
    "print(metadata['dx_type'].unique())\n",
    "print(metadata['sex'].unique())\n",
    "print(metadata['localization'].unique())\n",
    "print(metadata['dataset'].unique())\n",
    "\n",
    "metadata_encoded = metadata.join(pd.get_dummies(metadata['dx'], prefix='dx', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dx'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dx_type'], prefix='dx_type', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dx_type'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['sex'], prefix='sex', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['sex'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['localization'], prefix='localization', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['localization'])\n",
    "\n",
    "metadata_encoded = metadata_encoded.join(pd.get_dummies(metadata_encoded['dataset'], prefix='dataset', dtype=int))\n",
    "metadata_encoded = metadata_encoded.drop(columns=['dataset'])\n",
    "\n",
    "new_order = ['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
    "['histo' 'consensus' 'confocal' 'follow_up']\n",
    "['male' 'female' 'unknown']\n",
    "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
    " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
    "['vidir_modern' 'rosendahl' 'vienna_dias' 'vidir_molemax']\n",
    "index = ['image_id', 'dx_akiec', 'dx_bcc', 'dx_bkl', 'dx_df',\n",
    "       'dx_mel', 'dx_nv', 'dx_vasc', 'dx_type_confocal', 'dx_type_consensus',\n",
    "       'dx_type_follow_up', 'dx_type_histo', 'age', 'sex_female', 'sex_male',\n",
    "       'sex_unknown', 'localization_abdomen', 'localization_acral',\n",
    "       'localization_back', 'localization_chest', 'localization_ear',\n",
    "       'localization_face', 'localization_foot', 'localization_genital',\n",
    "       'localization_hand', 'localization_lower extremity',\n",
    "       'localization_neck', 'localization_scalp', 'localization_trunk',\n",
    "       'localization_unknown', 'localization_upper extremity',\n",
    "       'dataset_rosendahl', 'dataset_vidir_modern', 'dataset_vidir_molemax',\n",
    "       'dataset_vienna_dias', 'lesion_id']\n",
    "\n",
    "metadata_encoded = metadata_encoded[index]\n",
    "metadata_encoded = metadata_encoded.drop(columns=['lesion_id'])\n",
    "print(metadata_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27c79b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_encoded = metadata_encoded.set_index('image_id').T.to_dict('list')\n",
    "\n",
    "# print(len(metadata_encoded['ISIC_0027419']))\n",
    "# print(len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0b8c9",
   "metadata": {},
   "source": [
    "Image Processing + Input to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5beb293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAM10000/HAM10000_part1\\ISIC_0024306.jpg\n",
      "HAM10000/HAM10000_part2\\ISIC_0029306.jpg\n"
     ]
    }
   ],
   "source": [
    "#get the path for each image\n",
    "#ham10000_pt1 has the paths for all images in the ham10000_pt1 folder, same for pt2.\n",
    "ham10000_pt1 = glob('HAM10000/HAM10000_part1/*.jpg')\n",
    "ham1000_pt2 = glob('HAM10000/HAM10000_part2/*.jpg')\n",
    "\n",
    "print(ham10000_pt1[0])\n",
    "print(ham1000_pt2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d83080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the metadata a pandas dataframe\n",
    "\n",
    "def print_data(image_id, row, flattened_image_np, total_data, i):\n",
    "    \"\"\" \n",
    "    Function that prints the data so that differences can be spotted.\n",
    "    intended to be used inside of process data for testing.\n",
    "    image_id: string, the image id. (eg ISIC_0024306)\n",
    "    row: list, metadat info\n",
    "    flattened_image_np: np array, flattened image info\n",
    "    total_data: pandas df, the master dataframe\n",
    "    i: int, iterator\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"----------------------------\")\n",
    "    print()\n",
    "    print(\"image_id: \", image_id)\n",
    "    print(\"first 10 of the metadata: \", row[:10])\n",
    "    print(\"last 10 entries of the flattened_image_np array: \", flattened_image_np[-10:])\n",
    "    print(\"total data row that was just created: \", total_data.iloc[i].to_frame().T)\n",
    "    print()\n",
    "    \n",
    "def process_data(folder, data_frame):\n",
    "    \"\"\"\n",
    "    function that processes the data from HAM10000\n",
    "\n",
    "    folder: string, name of the folder that has the data\n",
    "    data_frame: PD dataframe, where the function stores the data. \n",
    "    \"\"\"\n",
    "    for i in range(len(folder)):\n",
    "        #open the image\n",
    "        path = folder[i]\n",
    "        image = Image.open(path)\n",
    "\n",
    "        image_id = path[24:len(path)-4]\n",
    "\n",
    "        #resize it, this will keep the aspect ratio\n",
    "        image.thumbnail((100, 100))\n",
    "\n",
    "        #make our image into a series of pixes, MxNx3\n",
    "        img_array = np.array(image) \n",
    "        #flatten the 3D matrix\n",
    "        flattened_array = img_array.flatten()\n",
    "        flattened_image_np = np.array(flattened_array) / 255\n",
    "\n",
    "        row = metadata_encoded[image_id] #the row of metadata that corresponds with this image\n",
    "\n",
    "        #total_data \n",
    "        row_np = np.array(row)\n",
    "\n",
    "        obs = np.concatenate((row_np, flattened_image_np))\n",
    "        obs_df = pd.DataFrame([obs])\n",
    "        data_frame = pd.concat([data_frame, obs_df], ignore_index=True)\n",
    "\n",
    "        if(i%1000 == 0):\n",
    "            #print_data(image_id, row, flattened_image_np, data_frame, i)\n",
    "            print(\"!! finished batch of 1000 !!\")\n",
    "            print(data_frame.shape)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b4e8fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! finished batch of 1000 !!\n",
      "!! finished batch of 1000 !!\n",
      "!! finished batch of 1000 !!\n",
      "!! finished batch of 1000 !!\n",
      "!! finished batch of 1000 !!\n",
      "(5000, 22534)\n"
     ]
    }
   ],
   "source": [
    "#DATA PROCESSING FOR GENERAL CLASSIFIERS\n",
    "\n",
    "#loop oer each image\n",
    "    #resize \n",
    "    #flatten the 3d array\n",
    "    #each row create a mapping\n",
    "    #process the metadata(ex: mapping labels to numbers)\n",
    "    #add all of the info to the accum numpy array \n",
    "#\n",
    "#create our accumulator dataframe\n",
    "total_data = pd.DataFrame()\n",
    "#process data for part 1\n",
    "total_data = process_data(ham10000_pt1, total_data)\n",
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1381e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 22534)\n"
     ]
    }
   ],
   "source": [
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "037a687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! finished batch of 1000 !!\n",
      "(5001, 22534)\n",
      "!! finished batch of 1000 !!\n",
      "(6001, 22534)\n",
      "!! finished batch of 1000 !!\n",
      "(7001, 22534)\n",
      "!! finished batch of 1000 !!\n",
      "(8001, 22534)\n",
      "!! finished batch of 1000 !!\n",
      "(9001, 22534)\n",
      "!! finished batch of 1000 !!\n",
      "(10001, 22534)\n",
      "total_data shape:  (10015, 22534)\n"
     ]
    }
   ],
   "source": [
    "#PROCESSING FOR PT 2:\n",
    "total_data = process_data(ham1000_pt2, total_data)\n",
    "\n",
    "print(\"total_data shape: \", total_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38e1947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.to_csv('HAM10000_general_classifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62641f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diide each RGB by 255 to get numbers in range 0 - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
