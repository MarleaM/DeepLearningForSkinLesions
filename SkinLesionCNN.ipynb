{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b958db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# selects training device\n",
    "# if a GPU is not available, run on the CPU (but GPU is much faster for CNNs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# load metadata\n",
    "metadata = pd.read_csv(\"HAM10000/HAM10000_metadata\")\n",
    "\n",
    "# converts the label, the diagnosis (dx), into numeric labels (0â€“6)\n",
    "labels = metadata[\"dx\"].unique()\n",
    "label_map = {name: i for i, name in enumerate(labels)}\n",
    "metadata[\"label\"] = metadata[\"dx\"].map(label_map)\n",
    "print(\"Label map:\", label_map)\n",
    "\n",
    "# map image ids to image files\n",
    "paths_part1 = glob(\"HAM10000/HAM10000_part1/*.jpg\")\n",
    "paths_part2 = glob(\"HAM10000/HAM10000_part2/*.jpg\")\n",
    "all_paths = paths_part1 + paths_part2\n",
    "\n",
    "id_to_path = {os.path.basename(p)[:-4]: p for p in all_paths}\n",
    "print(\"Total images found:\", len(id_to_path))\n",
    "\n",
    "# initialize lists to store image paths and their labels\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "for _, row in metadata.iterrows():\n",
    "    img_id = row[\"image_id\"]\n",
    "    if img_id in id_to_path:\n",
    "        image_paths.append(id_to_path[img_id])\n",
    "        image_labels.append(row[\"label\"])\n",
    "\n",
    "print(\"Total usable images:\", len(image_paths))\n",
    "\n",
    "# train/validation split\n",
    "# once we tune hyperparameters we can include a test set\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths,\n",
    "    image_labels,\n",
    "    test_size=0.2,\n",
    "    stratify=image_labels, # makes class proportions consistent for training and validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_paths), \"Val size:\", len(val_paths))\n",
    "\n",
    "# define image transforms for training images\n",
    "train_transform = transforms.Compose([\n",
    "    # make every image the same size\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    # helps model learn symmetry if lesion is flipped\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    # account for images being taken in different lighting conditions\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "\n",
    "    # CAN INSERT MORE TRANSFORMS HERE IF WE WANT TO TRY THEM\n",
    "\n",
    "    # convert PIL image into PyTorch tensor and scale pixel values from 0-255 to 0-1\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # standardize each channel (match what EfficientNet was trained on)\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# define image transforms for training images\n",
    "val_transform = transforms.Compose([\n",
    "    # make every image the same size\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    # convert PIL image into PyTorch tensor and scale pixel values from 0-255 to 0-1\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # standardize each channel (match what EfficientNet was trained on)\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# helper function that loads one image at a time and applies transformation\n",
    "def load_image_tensor(path, transform):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = transform(img)\n",
    "    return img\n",
    "\n",
    "# build EfficientNet-B2 Model\n",
    "weights = EfficientNet_B2_Weights.DEFAULT\n",
    "model = efficientnet_b2(weights=weights)\n",
    "\n",
    "num_classes = len(label_map) # we have 7 classes\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# define loss and optimizer\n",
    "\n",
    "# cross entropy loss is used for CNNs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# commonly used optimizer for EfficientNet over SGD\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "#################\n",
    "# TRAINING\n",
    "#################\n",
    "\n",
    "# define batch size - if training is too slow, increase it\n",
    "batch_size = 32\n",
    "\n",
    "# more epochs means more learning, but it takes longer... can overfit if too many\n",
    "epochs = 10\n",
    "\n",
    "# keep track of best validation accuracy over all epochs\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # model is now training\n",
    "    model.train()\n",
    "\n",
    "    # accum loss over all batches for current epoch\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # shuffle training data indices for current epoch\n",
    "    indices = np.random.permutation(len(train_paths))\n",
    "\n",
    "    # loop over batches\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        batch_idx = indices[start:start + batch_size]\n",
    "        batch_imgs = []\n",
    "        batch_labs = []\n",
    "\n",
    "        # Load batch into memory\n",
    "        for idx in batch_idx:\n",
    "            # get file path for image\n",
    "            path = train_paths[idx]\n",
    "            # get numeric label (0-6) for image\n",
    "            lab = train_labels[idx]\n",
    "            # open image, apply transform, and return tensor (C x H x W)\n",
    "            img_tensor = load_image_tensor(path, train_transform)\n",
    "\n",
    "            # collect image tensors and image labels\n",
    "            batch_imgs.append(img_tensor)\n",
    "            batch_labs.append(lab)\n",
    "\n",
    "        # turn batched tensors into single tensor (B x C x H x W) on GPU (if using GPU)\n",
    "        images = torch.stack(batch_imgs).to(device)\n",
    "        # create 1D tensor with int class labels (0-6)\n",
    "        labels = torch.tensor(batch_labs, dtype=torch.long).to(device)\n",
    "\n",
    "        ##### TRAINING STEP FOR EACH BATCH ####\n",
    "\n",
    "        # clear old gradients from previous batches\n",
    "        optimizer.zero_grad()\n",
    "        # send batch through CNN\n",
    "        outputs = model(images)\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update model weights using gradients... this is where learning occurs\n",
    "        optimizer.step()\n",
    "\n",
    "        # track total loss for this epoch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    #################\n",
    "    # VALIDATION\n",
    "    #################\n",
    "\n",
    "    # model is now in the mode for validation/testing\n",
    "    model.eval()\n",
    "    # count how many predictions are correct\n",
    "    correct = 0\n",
    "    # total num of predictions\n",
    "    total = 0\n",
    "\n",
    "    # no gradient tracking bc we are not training\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(val_paths), batch_size):\n",
    "            batch_paths = val_paths[start:start + batch_size]\n",
    "            batch_labs = val_labels[start:start + batch_size]\n",
    "\n",
    "            batch_imgs = []\n",
    "            for path in batch_paths:\n",
    "                img_tensor = load_image_tensor(path, val_transform)\n",
    "                batch_imgs.append(img_tensor)\n",
    "\n",
    "            images = torch.stack(batch_imgs).to(device)\n",
    "            labels = torch.tensor(batch_labs, dtype=torch.long).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # returns values, indices\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # compute validation accuracy\n",
    "    val_acc = correct / total\n",
    "    print(\"Epoch %d: loss=%.3f, val_acc=%.2f%%\" % (epoch + 1, running_loss, val_acc * 100))\n",
    "\n",
    "    # save best model so we can load it in more easily later\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # can do: model.load_state_dict(torch.load(\"best_effnet_b2_nodataset.pth\"))\n",
    "        torch.save(model.state_dict(), \"best_effnet_b2_nodataset.pth\")\n",
    "\n",
    "print(\"Training complete. Best validation accuracy:\", best_val_acc * 100)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
